{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "def rand_n_int(l, r, n):\n",
    "    s=[]\n",
    "    while(len(s)<n):\n",
    "        x=random.randint(l,r)\n",
    "        if x not in s:\n",
    "            s.append(x)\n",
    "    return s\n",
    "\n",
    "random.seed(time.time())\n",
    "\n",
    "data_arr = np.load(\"data_reduce.npy\")\n",
    "labels_pre = np.load(\"labels_full.npy\")\n",
    "labels_pre = labels_pre.reshape(-1,1)\n",
    "cates = max(labels_pre)[0]+1\n",
    "labels = []\n",
    "for i in range(labels_pre.shape[0]):\n",
    "    row = np.zeros(cates).tolist()\n",
    "    row[labels_pre[i][0]] = 1\n",
    "    labels.append(row)\n",
    "    \n",
    "labels = np.array(labels)    \n",
    "\n",
    "test_index = np.array(rand_n_int(0, data_arr.shape[0]-1, math.floor(data_arr.shape[0]*0.3)))\n",
    "train_index=[]\n",
    "for i in range(data_arr.shape[0]):\n",
    "    if i not in test_index:\n",
    "        train_index.append(i)\n",
    "train_index = np.array(train_index)\n",
    "data_train = data_arr[train_index,:]\n",
    "label_train = labels[train_index,:]\n",
    "data_test = data_arr[test_index,:]\n",
    "label_test = labels[test_index,:]\n",
    "\n",
    "x, y = Variable(torch.FloatTensor(data_train)), Variable(torch.FloatTensor(label_train))\n",
    "x_test, y_test = Variable(torch.FloatTensor(data_test)), Variable(torch.FloatTensor(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(time.time())\n",
    "seq_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(data_arr.shape[1], math.ceil(math.sqrt(data_arr.shape[1]*labels.shape[1]))),\n",
    "    torch.nn.Sigmoid(),\n",
    "    #torch.nn.Linear(math.ceil(math.sqrt(data_arr.shape[1]*labels.shape[1])), math.ceil(math.sqrt(data_arr.shape[1]*labels.shape[1]))),\n",
    "    #torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(math.ceil(math.sqrt(data_arr.shape[1]*labels.shape[1])), labels.shape[1]),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0 iteration. Loss=0.2641\n",
      "No.100 iteration. Loss=0.0057\n",
      "No.200 iteration. Loss=0.0033\n",
      "No.300 iteration. Loss=0.0023\n",
      "No.400 iteration. Loss=0.0018\n",
      "No.500 iteration. Loss=0.0015\n",
      "No.600 iteration. Loss=0.0013\n",
      "No.700 iteration. Loss=0.0012\n",
      "No.800 iteration. Loss=0.0011\n",
      "No.900 iteration. Loss=0.0010\n",
      "No.1000 iteration. Loss=0.0009\n",
      "No.1100 iteration. Loss=0.0009\n",
      "No.1200 iteration. Loss=0.0008\n",
      "No.1300 iteration. Loss=0.0008\n",
      "No.1400 iteration. Loss=0.0007\n",
      "No.1500 iteration. Loss=0.0007\n",
      "No.1600 iteration. Loss=0.0007\n",
      "No.1700 iteration. Loss=0.0007\n",
      "No.1800 iteration. Loss=0.0007\n",
      "No.1900 iteration. Loss=0.0006\n"
     ]
    }
   ],
   "source": [
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(seq_net.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "for t in range(2000):\n",
    "    prediction = seq_net(x)                                      # 用网络预测一下\n",
    "    loss = loss_func(prediction, y)                          # 计算损失\n",
    "    optimizer.zero_grad()                                    # 清除上一步的梯度\n",
    "    loss.backward()                                          # 反向传播, 计算梯度\n",
    "    optimizer.step()                                         # 优化一步\n",
    "    if t % 100 == 0:\n",
    "        print('No.%d iteration. Loss=%.4f' % (t, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9163\n"
     ]
    }
   ],
   "source": [
    "out = seq_net(x_test).detach().numpy()\n",
    "out_arr = np.array([])\n",
    "for i in range(out.shape[0]):\n",
    "    out_arr = np.append(out_arr, [np.argmax(out[i])])\n",
    "out_arr = out_arr.astype(int)\n",
    "correct = 0\n",
    "for i in range(label_test.shape[0]):\n",
    "    if label_test[i][out_arr[i]] == 1:\n",
    "        correct+=1\n",
    "print(\"Accuracy: %.4f\" % (correct/label_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
